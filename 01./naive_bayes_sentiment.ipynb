{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "551c6b0f",
   "metadata": {},
   "source": [
    "# Naive Bayes Model for Binary Classification\n",
    "\n",
    "This notebook performs `binary sentiment classification` with `Naive Bayes model`.\n",
    "\n",
    "The dataset used is `GoEmotions` which contains 58k comments from Reddit provided by Google.\n",
    "- It is taken directly from here (https://github.com/google-research/google-research/tree/master/goemotions).\n",
    "\n",
    "Flow of the notebook is as follows:\n",
    "1. Data Processing\n",
    "2. Model Training\n",
    "3. Making Predictions\n",
    "4. Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a210669",
   "metadata": {},
   "source": [
    "First, import libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b7fe22b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# download packages if they are not installed\n",
    "# !pip install nltk\n",
    "# !pip install emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29e6e7fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data path: /Users/hjy/nlp_models/naive_bayes/nb_data\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import emoji\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "import os\n",
    "import json\n",
    "\n",
    "path = os.getcwd() + '/nb_data'\n",
    "print(f'Data path: {path}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a4ab09c",
   "metadata": {},
   "source": [
    "## 1. Data Processing\n",
    "\n",
    "For the simplicity of the model (that is to perform binary classification),\n",
    "- Take the first emotion if there are several emotions labeled.\n",
    "- Convert sentiments to either `positive(1)` or `negative(0)`. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d5898da9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['admiration', 'amusement', 'anger', 'annoyance', 'approval', 'caring', 'confusion', 'curiosity', 'desire', 'disappointment', 'disapproval', 'disgust', 'embarrassment', 'excitement', 'fear', 'gratitude', 'grief', 'joy', 'love', 'nervousness', 'optimism', 'pride', 'realization', 'relief', 'remorse', 'sadness', 'surprise', 'neutral']\n",
      "\n",
      " {'positive': ['amusement', 'excitement', 'joy', 'love', 'desire', 'optimism', 'caring', 'pride', 'admiration', 'gratitude', 'relief', 'approval'], 'negative': ['fear', 'nervousness', 'remorse', 'embarrassment', 'disappointment', 'sadness', 'grief', 'disgust', 'anger', 'annoyance', 'disapproval'], 'ambiguous': ['realization', 'surprise', 'curiosity', 'confusion']}\n"
     ]
    }
   ],
   "source": [
    "# call data\n",
    "columns = ('text', 'emotion', 'id')\n",
    "\n",
    "train = pd.read_csv(path + '/train.csv', sep='\\t', names=columns)\n",
    "test = pd.read_csv(path + '/test.csv', sep='\\t', names=columns)\n",
    "\n",
    "\n",
    "# get emotion mapping data\n",
    "emotions = []\n",
    "with open(path + '/emotions.txt', 'r') as file:\n",
    "    for line in file.readlines():\n",
    "        emotions.append(line.strip('\\n'))\n",
    "    \n",
    "print(emotions)\n",
    "\n",
    "# get sentiment dictionary\n",
    "with open(path + '/sentiment_dict.json', 'r') as file:\n",
    "    sent_dict = json.load(file)\n",
    "    \n",
    "print('\\n', sent_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a608e5e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def num2sent(numbs, emotions=emotions, sent_dict=sent_dict):\n",
    "    '''\n",
    "    return 1 if the first emotion is positive, 0 if emotion is negative, and -1 if ambiguous\n",
    "    '''\n",
    "    # get the first emotion\n",
    "    numb = int(numbs.split(',')[0])\n",
    "    \n",
    "    # set label to 1 if positive, 0 if negative and -1 if ambiguous\n",
    "    sent2num = {'positive':int(1), 'negative':int(0), 'ambiguous':int(-1)}\n",
    "    \n",
    "    for senti in sent_dict.keys():\n",
    "        if emotions[numb] in sent_dict[senti]:\n",
    "            return sent2num[senti]\n",
    "\n",
    "        \n",
    "train['emotion'] = train['emotion'].map(num2sent)\n",
    "test['emotion'] = test['emotion'].map(num2sent)\n",
    "\n",
    "train = train[train['emotion'] > -1]\n",
    "test = test[test['emotion'] > -1]\n",
    "\n",
    "\n",
    "train_x = train['text'].to_numpy()\n",
    "train_y = train['emotion'].to_numpy()\n",
    "\n",
    "test_x = test['text'].to_numpy()\n",
    "test_y = test['emotion'].to_numpy()\n",
    "\n",
    "del train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "118aa8da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train examples: 26098 \n",
      "Number of test examples: 3248\n",
      "\n",
      "Training data examples:\n",
      "\n",
      "Text data: WHY THE FUCK IS BAYLESS ISOING\n",
      "Label: 0.0\n",
      "\n",
      "Text data: To make her feel threatened\n",
      "Label: 0.0\n",
      "\n",
      "Text data: Dirty Southern Wankers\n",
      "Label: 0.0\n",
      "\n",
      "Text data: Yes I heard abt the f bombs! That has to be why. Thanks for your reply:) until then hubby and I will anxiously wait üòù\n",
      "Label: 1.0\n",
      "\n",
      "Text data: We need more boards and to create a bit more space for [NAME]. Then we‚Äôll be good.\n",
      "Label: 1.0\n",
      "\n",
      "Text data: Damn youtube and outrage drama is super lucrative for reddit\n",
      "Label: 1.0\n",
      "\n",
      "Text data: Aww... she'll probably come around eventually, I'm sure she was just jealous of [NAME]... I mean, what woman wouldn't be! lol \n",
      "Label: 1.0\n",
      "\n",
      "Text data: R/sleeptrain Might be time for some sleep training. Take a look and try to feel out what's right for your family.\n",
      "Label: 1.0\n",
      "\n",
      "Text data: [NAME] - same fucking problem, slightly better command of the English language.\n",
      "Label: 0.0\n",
      "\n",
      "Text data: Shit, I guess I accidentally bought a Pay-Per-View boxing match\n",
      "Label: 0.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print number of train and test examples\n",
    "print(f'Number of train examples: {len(train_x)} \\nNumber of test examples: {len(test_x)}')\n",
    "\n",
    "# print n examples\n",
    "n = 10\n",
    "\n",
    "print('\\nTraining data examples:\\n')\n",
    "for i in range(n):\n",
    "    print(f'Text data: {train_x[i]}\\nLabel: {train_y[i]}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba7e9ed1",
   "metadata": {},
   "source": [
    "There are more data which is positive than negative. Later, we will multiply prior to compensate the imbalance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ffedf2d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# count the ratio of positive and negative sentiment in train and test data\n",
    "\n",
    "# get data\n",
    "def len_pos_neg(np_arr):\n",
    "    len_pos = len(np_arr[np_arr == 1])\n",
    "    return [len_pos, len(np_arr) - len_pos]\n",
    "\n",
    "train_ratio = len_pos_neg(train_y)\n",
    "test_ratio = len_pos_neg(test_y)\n",
    "\n",
    "labels = ['Positive', 'Negative']\n",
    "colors = ['#ff9999', '#ffc000']\n",
    "\n",
    "# draw plots\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.pie(train_ratio, labels=labels, autopct='%.1f%%', startangle=260, counterclock=False, colors=colors)\n",
    "plt.title('Train data')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.pie(test_ratio, labels=labels, autopct='%.1f%%', startangle=260, counterclock=False, colors=colors)\n",
    "plt.title('Test data')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8614d2c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set data pipeline\n",
    "def process(s):\n",
    "    '''process a string sentence data in to a list of tokenized words'''\n",
    "    \n",
    "    # First, delete '[NAME]' entities\n",
    "    s = s.replace('[NAME]', '')\n",
    "    s = s.replace('[RELIGION]', '')\n",
    "    \n",
    "    # set every letter to lower case\n",
    "    s = s.lower()\n",
    "    \n",
    "    # process emojis\n",
    "    s = emoji.demojize(s)\n",
    "    \n",
    "    # tokenize the sentence with RegexpTokenizer\n",
    "    tokenizer = RegexpTokenizer('\\w+|\\$[\\d\\.]+|\\S+')\n",
    "    s_token = tokenizer.tokenize(s)\n",
    "    \n",
    "    return s_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d9b6eaa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw text: WHY THE FUCK IS BAYLESS ISOING \n",
      "processed : ['why', 'the', 'fuck', 'is', 'bayless', 'isoing'] \n",
      "\n",
      "Raw text: To make her feel threatened \n",
      "processed : ['to', 'make', 'her', 'feel', 'threatened'] \n",
      "\n",
      "Raw text: Dirty Southern Wankers \n",
      "processed : ['dirty', 'southern', 'wankers'] \n",
      "\n",
      "Raw text: Yes I heard abt the f bombs! That has to be why. Thanks for your reply:) until then hubby and I will anxiously wait üòù \n",
      "processed : ['yes', 'i', 'heard', 'abt', 'the', 'f', 'bombs', '!', 'that', 'has', 'to', 'be', 'why', '.', 'thanks', 'for', 'your', 'reply', ':)', 'until', 'then', 'hubby', 'and', 'i', 'will', 'anxiously', 'wait', ':squinting_face_with_tongue:'] \n",
      "\n",
      "Raw text: We need more boards and to create a bit more space for [NAME]. Then we‚Äôll be good. \n",
      "processed : ['we', 'need', 'more', 'boards', 'and', 'to', 'create', 'a', 'bit', 'more', 'space', 'for', '.', 'then', 'we', '‚Äôll', 'be', 'good', '.'] \n",
      "\n",
      "Raw text: Damn youtube and outrage drama is super lucrative for reddit \n",
      "processed : ['damn', 'youtube', 'and', 'outrage', 'drama', 'is', 'super', 'lucrative', 'for', 'reddit'] \n",
      "\n",
      "Raw text: Aww... she'll probably come around eventually, I'm sure she was just jealous of [NAME]... I mean, what woman wouldn't be! lol  \n",
      "processed : ['aww', '...', 'she', \"'ll\", 'probably', 'come', 'around', 'eventually', ',', 'i', \"'m\", 'sure', 'she', 'was', 'just', 'jealous', 'of', '...', 'i', 'mean', ',', 'what', 'woman', 'wouldn', \"'t\", 'be', '!', 'lol'] \n",
      "\n",
      "Raw text: R/sleeptrain Might be time for some sleep training. Take a look and try to feel out what's right for your family. \n",
      "processed : ['r', '/sleeptrain', 'might', 'be', 'time', 'for', 'some', 'sleep', 'training', '.', 'take', 'a', 'look', 'and', 'try', 'to', 'feel', 'out', 'what', \"'s\", 'right', 'for', 'your', 'family', '.'] \n",
      "\n",
      "Raw text: [NAME] - same fucking problem, slightly better command of the English language. \n",
      "processed : ['-', 'same', 'fucking', 'problem', ',', 'slightly', 'better', 'command', 'of', 'the', 'english', 'language', '.'] \n",
      "\n",
      "Raw text: Shit, I guess I accidentally bought a Pay-Per-View boxing match \n",
      "processed : ['shit', ',', 'i', 'guess', 'i', 'accidentally', 'bought', 'a', 'pay', '-per-view', 'boxing', 'match'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# test process function\n",
    "for i in range(n):\n",
    "    example_s = train_x[i]\n",
    "    print(f'Raw text: {example_s} \\nprocessed : {process(example_s)} \\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6afa76a",
   "metadata": {},
   "source": [
    "## 2. Model Training\n",
    "\n",
    "To get the frequency of `(word, class)` pair from the train data, I implemented `get_freq` but `utils.build_freqs` does the same job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "795477a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_freq(dd, train_x, train_y):\n",
    "    '''\n",
    "    Get frequency dictionary from the training data.\n",
    "    input:\n",
    "        dd : a defaultdict of integer.\n",
    "        train_x : list of tokened sentences of training data.\n",
    "        train_y : list of 0 or 1 corresponding to the train_x. \n",
    "    return:\n",
    "        result : dictionary of (key, value) = (word label pair, frequency).\n",
    "    '''\n",
    "    for sentence, label in zip(train_x, train_y):\n",
    "        for word in process(sentence):\n",
    "            dd[(word, label)] += 1\n",
    "\n",
    "    return dd\n",
    "\n",
    "# count frequency dictionary from train_x and train_y.\n",
    "freqs = get_freq(defaultdict(int), train_x, train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5bd8dcd",
   "metadata": {},
   "source": [
    "To train Naive model is to compute `log_prior` and `log_likelihood` from the training data.  \n",
    "\n",
    "Let's compute the Naive Bayes in the form:\n",
    "$$\n",
    "NB(s) = log\\frac{P(Pos)}{P(Neg)} + \\sum^{m}_{i=1} log\\frac{P(w_i|Pos)}{P(w_i|Neg)}\n",
    "$$\n",
    "with Laplacian smoothing on conditional probability:\n",
    "$$\n",
    "P(w|class) = \\frac{freq(w, class) + 1}{N_{class} + V_{class}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "22dcc8f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_naive_bayes(freqs, train_x, train_y):\n",
    "    '''\n",
    "    Train Naive Bayes model, that is, get prior and likelihood from the training data.\n",
    "    return:\n",
    "        log_prior : an integer. P(Pos) / P(Neg) value.\n",
    "        log_likelihood : a dictionary of (key, value) = (word, log likelihood)\n",
    "    '''\n",
    "    # log_likelihood relies on words\n",
    "    log_likelihood = dict()\n",
    "    # log prior value relies on the corpus\n",
    "    log_prior = 0\n",
    "\n",
    "    # get unique words from the frequency dict\n",
    "    vocab = list(set([k[0] for k in freqs.keys()]))\n",
    "    V = len(vocab)\n",
    "\n",
    "    # get N_pos and N_neg\n",
    "    N_pos = N_neg = 0\n",
    "    for pair in freqs.keys():\n",
    "        # if label is 1, the word is positive.\n",
    "        if pair[1] == 1:\n",
    "            N_pos += freqs[pair]\n",
    "        # if label is 0, the word is negative.\n",
    "        else:\n",
    "            N_neg += freqs[pair]\n",
    "\n",
    "    # get log likelihood\n",
    "    for w in vocab:\n",
    "        # get positive and negative frequency of word w.\n",
    "        freq_pos = freqs.get((w, 1), 0)\n",
    "        freq_neg = freqs.get((w, 0), 0)\n",
    "\n",
    "        # get P(w|Pos) and P(w|Neg).\n",
    "        p_w_pos = (freq_pos + 1) / (N_pos + V)\n",
    "        p_w_neg = (freq_neg + 1) / (N_neg + V)\n",
    "\n",
    "        log_likelihood[w] = np.log(p_w_pos) - np.log(p_w_neg)\n",
    "\n",
    "    # to compute log_prior,\n",
    "    # get the number of positive and negative labels\n",
    "    num_label = len(train_y)\n",
    "    num_pos = len(train_y[train_y == 1])\n",
    "    num_neg = len(train_y[train_y == 0])\n",
    "\n",
    "    # log prior = log(P(Pos)) - log(P(Neg))\n",
    "    log_prior = np.log(num_pos / num_label) - np.log(num_neg / num_label)\n",
    "\n",
    "    return log_prior, log_likelihood, vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "30a10c6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log prior: 0.6163959534768829\n",
      "log likelihood for pair (bottle, 1): -0.6573034506496942\n",
      "log likelihood for pair (figured, 1): 0.7206226607996786\n",
      "log likelihood for pair (globally, 1): 0.18999440973750836\n",
      "log likelihood for pair (sales, 1): -0.5031527708224353\n",
      "log likelihood for pair (civilizations, 1): -1.6017650594905462\n",
      "log likelihood for pair (yaaaaaas, 1): 0.18999440973750836\n",
      "log likelihood for pair (*), 1): 0.18999440973750836\n",
      "log likelihood for pair (tdagarim, 1): 0.18999440973750836\n",
      "log likelihood for pair (us, 1): -0.03859874634426497\n",
      "log likelihood for pair (scarecrow, 1): 0.5954595178456721\n"
     ]
    }
   ],
   "source": [
    "# get log prior and log likelihood from the training data\n",
    "# so that we can train on test data.\n",
    "log_prior, log_likelihood, vocab = train_naive_bayes(freqs, train_x, train_y)\n",
    "\n",
    "print(f'log prior: {log_prior}')\n",
    "\n",
    "for i in range(n):\n",
    "    print(f'log likelihood for pair ({vocab[i]}, 1): {log_likelihood[(vocab[i])]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b592ec9",
   "metadata": {},
   "source": [
    "## 3. Making Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b182d2ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_naive_bayes(s, log_prior, log_likelihood):\n",
    "    '''\n",
    "    input:\n",
    "        s : a list. Input sentence.\n",
    "        log_prior : log prior from trained naive bayes.\n",
    "        log_likelihood : log likelihood from trained naive bayes.\n",
    "    return:\n",
    "        log_prob : float between 0 and 1. probability that s is positive.\n",
    "    '''    \n",
    "\n",
    "    words = process(s)\n",
    "    log_prob = 0\n",
    "\n",
    "    for w in words:\n",
    "        if w in log_likelihood:\n",
    "            log_prob += log_likelihood[w]\n",
    "\n",
    "    log_prob += log_prior\n",
    "\n",
    "    return log_prob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c33eeb5f",
   "metadata": {},
   "source": [
    "Now let's run some tests with the trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f14f26db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction: 3.5899659770696997\n"
     ]
    }
   ],
   "source": [
    "# predict probability on some test data.\n",
    "test_data = 'hope you get well soon. it hurts to see you ill üò¢'\n",
    "print('prediction:', predict_naive_bayes(test_data, log_prior, log_likelihood))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95913d57",
   "metadata": {},
   "source": [
    "This example seems to predict right. Let's look at the following examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c406ce9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction: -0.9631403029841944\n"
     ]
    }
   ],
   "source": [
    "test_data = 'the class was in a terrible mood...'\n",
    "print('prediction:', predict_naive_bayes(test_data, log_prior, log_likelihood))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "18f38c6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction: 1.7861563324372813\n"
     ]
    }
   ],
   "source": [
    "test_data = 'the class was in a terrible mood... haha...'\n",
    "print('prediction:', predict_naive_bayes(test_data, log_prior, log_likelihood))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22ede4fa",
   "metadata": {},
   "source": [
    "#### The model takes it hard to predict sarcastic or euphemistic contexts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c18f582e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction: 0.6163959534768829\n",
      "Are \"boooooring\" and \"log_prior\" the same in their value?: True\n"
     ]
    }
   ],
   "source": [
    "test_data = 'boooooring'\n",
    "prob = predict_naive_bayes(test_data, log_prior, log_likelihood)\n",
    "\n",
    "print('prediction:', prob)\n",
    "print(f'Are \"{test_data}\" and \"log_prior\" the same in their value?: {prob == log_prior}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42ccf566",
   "metadata": {},
   "source": [
    "#### Note that the word which do not appear in the corpus is not actually computed. \n",
    "\n",
    "This is because Naive Bayes rely on word frequency of the given corpus. In later models, this without-vocab words are named 'unknown words' and dealt with fresh ideas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "665b6a56",
   "metadata": {},
   "source": [
    "## 4. Evaluation\n",
    "\n",
    "To evaluate the model, we need to transform the data into a labeled form. That is, we need to convert the data gained by `predict_naive_bayes` into binary (`1` or `0`) form. \n",
    "\n",
    "Note that the neutral value of `log_prob` is `0`, not `1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6d8a200c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sign(log_prob):\n",
    "    return 1 if log_prob > 0 else 0\n",
    "\n",
    "def get_accuracy(test_x, test_y, log_prior, log_likelihood):\n",
    "    '''return accuracy of the prediction on test data'''\n",
    "    \n",
    "    matches = 0\n",
    "\n",
    "    for s, label in zip(test_x, test_y):\n",
    "        l_prob = predict_naive_bayes(s, log_prior, log_likelihood)\n",
    "        if sign(l_prob) == label:\n",
    "            matches += 1\n",
    "            \n",
    "    return matches / len(test_x) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cb69aa06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81.71182266009852\n"
     ]
    }
   ],
   "source": [
    "# get model accuray on the test data\n",
    "accuracy = get_accuracy(test_x, test_y, log_prior, log_likelihood)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0229c4a2",
   "metadata": {},
   "source": [
    "#### We have achieved 81% accuracy with Naive Bayes Model!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
